{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_include = [\"OWNER\",\"TITLE\", \"ABSTRACT\", \"SERVICETYPE\", \"SERVICELINK\", \"KEYWORDS\"]\n",
    "fields_to_output = [\"OWNER\",\"TITLE\", \"SERVICETYPE\", \"SERVICELINK\"]\n",
    "url_github_repo = \"https://github.com/davidoesch/geoservice_harvester_poc/blob/main/data/\"\n",
    "url_github_repo_suffix = \"?raw=true\"\n",
    "url_geoservices_CH_csv = \"{}geoservices_CH.csv{}\".format(url_github_repo,url_github_repo_suffix)\n",
    "a = 'Strassen auswertung system'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_delimiters(word_list_with_delimiters: List[str]) -> List[str]:\n",
    "    \"\"\"Take care of left over delimiters, split strings even if in qoutes\n",
    "        Return a list of words \"\"\"\n",
    "    delimiters = [\";\", \",\"]\n",
    "\n",
    "    new_word_list = []\n",
    "\n",
    "    for word in word_list_with_delimiters:\n",
    "        if (any(delimiter in word for delimiter in delimiters)):\n",
    "            splitted_words = re.split(r',|;', word)\n",
    "            for splitted_word_ in splitted_words:\n",
    "                new_word_list.append(splitted_word_)\n",
    "        else:\n",
    "            new_word_list.append(word)\n",
    "    return new_word_list\n",
    "\n",
    "def load_data():\n",
    "    dataframe = pd.read_csv(url_geoservices_CH_csv, usecols=fields_to_include)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = split_delimiters(shlex.split(a))\n",
    "dataframe_some_cols = load_data()\n",
    "result = dataframe_some_cols[dataframe_some_cols.apply(lambda dataset: dataset.astype(str).str.contains(res[0], case=False).any(), axis=1)]\n",
    "result =result.fillna(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF ranking of the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['tfidf'] = result.apply(lambda row: utils.ranking_tfidf(row['ABSTRACT']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Innerortsstrecken (IO) auf den Kantonsstrassen gemäss Strassengesetzt (SAR 751.100). Die Datenhaltung erfolgt im ESRI Modul \"Roads&Highways\". Innerortsstrecken (IO) auf den Kantonsstrassen gemäss Strassengesetzt (SAR 751.100). Die Datenhaltung erfolgt im ESRI Modul \"Roads&Highways\". None',\n",
       " ([('none', 1.0),\n",
       "   ('datenhaltung', 0.82),\n",
       "   ('erfolgt', 0.82),\n",
       "   ('esri', 0.82),\n",
       "   ('highway', 0.82),\n",
       "   ('modul', 0.82),\n",
       "   ('road', 0.82),\n",
       "   ('100', 0.71),\n",
       "   ('751', 0.71),\n",
       "   ('gemäss', 0.71),\n",
       "   ('innerortsstrecken', 0.71),\n",
       "   ('io', 0.71),\n",
       "   ('kantonsstrassen', 0.71),\n",
       "   ('sar', 0.71),\n",
       "   ('strassengesetzt', 0.71)],\n",
       "  'german'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[690]['ABSTRACT'], result.loc[690]['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Das Strassennetz als Teil des Topic Transportation des swissTLMRegio Produktes von swisstopo beschreibt die verschiedenen Elemente im Zusammenhang mit dem Verkehr / Transport. Es gibt Informationen über: Zollämter (CustomsOffice), wichtige Strassenknoten (Interchange), Auffahrtsrampen (Ramp), Strassen und Wege (Road), Autofähren (Ship) und Verkehrsinformationen zu den Strassen (TrafficInfo). Das detaillierte Verkehrsregime (Abbiegeverbote, Einbahnstrassen, usw.) ist nicht enthalten. Öffentliche Daten der Bundes Geodaten-Infrastruktur (BGDI) (Revision: wms-bgdi: 974b958 mapfile_include: 40688b8)',\n",
       " ([('bgdi', 0.53),\n",
       "   ('transport', 0.52),\n",
       "   ('strassen', 0.46),\n",
       "   ('abbiegeverbot', 0.41),\n",
       "   ('detailliert', 0.41),\n",
       "   ('einbahnstrassen', 0.41),\n",
       "   ('enthalten', 0.41),\n",
       "   ('usw', 0.41),\n",
       "   ('verkehrsregim', 0.41),\n",
       "   ('40688b8', 0.27),\n",
       "   ('974b958', 0.27),\n",
       "   ('bund', 0.27),\n",
       "   ('daten', 0.27),\n",
       "   ('geodaten', 0.27),\n",
       "   ('infrastruktur', 0.27),\n",
       "   ('mapfile_includ', 0.27),\n",
       "   ('revis', 0.27),\n",
       "   ('wms', 0.27),\n",
       "   ('öffentlich', 0.27),\n",
       "   ('beschreibt', 0.26),\n",
       "   ('element', 0.26),\n",
       "   ('produkt', 0.26),\n",
       "   ('strassennetz', 0.26),\n",
       "   ('swisstlmregio', 0.26),\n",
       "   ('swisstopo', 0.26),\n",
       "   ('teil', 0.26),\n",
       "   ('topic', 0.26),\n",
       "   ('verkehr', 0.26),\n",
       "   ('verschiedenen', 0.26),\n",
       "   ('zusammenhang', 0.26),\n",
       "   ('auffahrtsrampen', 0.23),\n",
       "   ('autofähren', 0.23),\n",
       "   ('customsoffic', 0.23),\n",
       "   ('gibt', 0.23),\n",
       "   ('informationen', 0.23),\n",
       "   ('interchang', 0.23),\n",
       "   ('ramp', 0.23),\n",
       "   ('road', 0.23),\n",
       "   ('ship', 0.23),\n",
       "   ('strassenknoten', 0.23),\n",
       "   ('trafficinfo', 0.23),\n",
       "   ('verkehrsinformationen', 0.23),\n",
       "   ('wege', 0.23),\n",
       "   ('wichtig', 0.23),\n",
       "   ('zollämter', 0.23)],\n",
       "  'german'),\n",
       " 'BGDI Geodaten',\n",
       " 'Strassennetz swissTLMRegio')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[20123]['ABSTRACT'], result.loc[20123]['tfidf'], result.loc[20123]['KEYWORDS'], result.loc[20123]['TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement of the TF-IDF with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# abstract = result.loc[20123]['ABSTRACT']\u001b[39;00m\n\u001b[0;32m      2\u001b[0m abstract \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDas Strassennetz als Teil des Topic Transportation des swissTLMRegio Produktes von swisstopo beschreibt die verschiedenen Elemente im Zusammenhang mit dem Verkehr / Transport. Es gibt Informationen über: Zollämter (CustomsOffice), wichtige Strassenknoten (Interchange), Auffahrtsrampen (Ramp), Strassen und Wege (Road), Autofähren (Ship) und Verkehrsinformationen zu den Strassen (TrafficInfo). Öffentliche Daten der Bundes Geodaten-Infrastruktur (BGDI)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m utils\u001b[39m.\u001b[39mrank_results_lsi(abstract, split_delimiters(shlex\u001b[39m.\u001b[39msplit(a)))\n",
      "File \u001b[1;32mc:\\Users\\ma1021525\\OneDrive - FHNW\\Documents\\Projects\\git\\Geoharvester\\server\\app\\processing\\utils.py:71\u001b[0m, in \u001b[0;36mrank_results_lsi\u001b[1;34m(document, query)\u001b[0m\n\u001b[0;32m     69\u001b[0m sentences \u001b[39m=\u001b[39m sent_tokenize(document, language \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgerman\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     70\u001b[0m words \u001b[39m=\u001b[39m (word_tokenize(sentence, language\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgerman\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences)\n\u001b[1;32m---> 71\u001b[0m documents_matrix \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39;49mfit_transform(words)\n\u001b[0;32m     72\u001b[0m query_matrix \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39mfit_transform(query)\n\u001b[0;32m     73\u001b[0m \u001b[39m# Perform LSI on the document matrix\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2121\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2116\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2117\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2118\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2119\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2120\u001b[0m )\n\u001b[1;32m-> 2121\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2123\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1377\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1369\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1370\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m             )\n\u001b[0;32m   1375\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1380\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1264\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   1263\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1264\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1265\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1266\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         doc \u001b[39m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32mc:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mapply to a document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m    preprocessed string\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> 69\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m accent_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     doc \u001b[39m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# abstract = result.loc[20123]['ABSTRACT']\n",
    "abstract = \"Das Strassennetz als Teil des Topic Transportation des swissTLMRegio Produktes von swisstopo beschreibt die verschiedenen Elemente im Zusammenhang mit dem Verkehr / Transport. Es gibt Informationen über: Zollämter (CustomsOffice), wichtige Strassenknoten (Interchange), Auffahrtsrampen (Ramp), Strassen und Wege (Road), Autofähren (Ship) und Verkehrsinformationen zu den Strassen (TrafficInfo). Öffentliche Daten der Bundes Geodaten-Infrastruktur (BGDI)\"\n",
    "utils.rank_results_lsi(abstract, split_delimiters(shlex.split(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.asarray(query.sum(axis=0)).ravel()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20412415, 0.19245009, 0.19245009, 0.20412415, 0.37796447,\n",
       "       0.37796447, 0.19245009, 0.20412415, 0.37796447, 0.20412415,\n",
       "       0.19245009, 0.37796447, 0.40824829, 0.20412415, 0.20412415,\n",
       "       0.19245009, 0.37796447, 0.19245009, 0.20412415, 0.19245009,\n",
       "       0.37796447, 0.19245009, 0.20412415, 0.20412415, 0.19245009,\n",
       "       0.19245009, 0.19245009, 0.38490018, 0.19245009, 0.20412415,\n",
       "       0.20412415, 0.20412415, 0.20412415, 0.20412415, 0.19245009,\n",
       "       0.20412415, 0.20412415, 0.38490018, 0.20412415, 0.19245009,\n",
       "       0.20412415, 0.20412415, 0.19245009, 0.19245009, 0.19245009,\n",
       "       0.19245009, 0.20412415, 0.37796447, 0.19245009])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.asarray(doc.sum(axis=0)).ravel()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['road', 'asset', 'management', 'system']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoharvester",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c031072c482ff12c1b8627010cd074fb6af482daeb686bcc3fbabf1c7aa304d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
