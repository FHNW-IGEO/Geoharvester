{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma1021525\\AppData\\Local\\Temp\\ipykernel_31572\\3242299578.py:7: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys, os\n",
    "from gpt4all import GPT4All\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from deep_translator import GoogleTranslator\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "sys.path.append(\"\\\\\".join(os.getcwd().split(\"\\\\\")[:-1]))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n",
    "from scraper import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(os.path.join(\"/\".join(os.getcwd().split(\"\\\\\")[:-1]),\n",
    "                                   'preprocessing','data/merged_data.pkl'))\n",
    "# define the language model (Llama with 8 billion parameters is about 4.66 GB)\n",
    "model = GPT4All('Meta-Llama-3-8B-Instruct.Q4_0.gguf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n"
     ]
    }
   ],
   "source": [
    "language_dict = {'english':('EN', 'ENG'), 'french':('FR','FRA'), 'german':('DE','DEU'), 'italian':('IT','ITA'), 'not_found':('NA','NAN')}\n",
    "data['lang_3'] = data.apply(lambda row: language_dict[detect_language(row['abstract'], not_found=True)][1], axis=1)\n",
    "data['lang_2'] = data.apply(lambda row: language_dict[detect_language(row['abstract'], not_found=True)][0], axis=1)\n",
    "# for idx, row in data.iterrows():\n",
    "#     if row['abstract'] != 'nan':\n",
    "#         if language_dict[detect_language(row['abstract_it'])][1] != 'ITA':\n",
    "#             trnd = GoogleTranslator(source='auto', target='ita').translate(row['abstract'])\n",
    "#             data.loc[idx, 'abstract_it'] = trnd\n",
    "#         if language_dict[detect_language(row['abstract_de'])][1] != 'DEU':\n",
    "#             trnd = GoogleTranslator(source='auto', target='de').translate(row['abstract'])\n",
    "#             data.loc[idx, 'abstract_de'] = trnd\n",
    "#         if language_dict[detect_language(row['abstract_fr'])][1] != 'FRA':\n",
    "#             trnd = GoogleTranslator(source='auto', target='fr').translate(row['abstract'])\n",
    "#             data.loc[idx, 'abstract_fr'] = trnd\n",
    "#         if language_dict[detect_language(row['abstract_en'])][1] != 'ENG':\n",
    "#             trnd = GoogleTranslator(source='auto', target='en').translate(row['abstract'])\n",
    "#             data.loc[idx, 'abstract_en'] = trnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract keywords with a local Llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5939"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['abstract_w_count'] = data.apply(lambda x: len(x['abstract'].split(' ')), axis=1)\n",
    "data.apply(lambda x: 'nan' if x['abstract'].startswith(('??','Es werden die Daten im Zeitraum','Link zu Metadaten:',\n",
    "                                                'https:',\n",
    "                                                'geo@bs.ch',\n",
    "                                                'info.geoportal@be.ch',\n",
    "                                                'sit@jura.ch',\n",
    "                                                'geodaten@sg.ch',\n",
    "                                                'info@example.com',\n",
    "                                                'agi@tg.ch',\n",
    "                                                'mail@lisag.ch',\n",
    "                                                'gis@bd.zh.ch',\n",
    "                                                'info.diffusion@vd.ch',\n",
    "                                                'webgis@swisstopo.ch'))\n",
    "                                                else x['abstract'], axis=1)\n",
    "len(data[(data['abstract'] != 'nan') &\n",
    "     (data['abstract'] != data['title']) &\n",
    "     (data['abstract_w_count']>4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]c:\\Users\\ma1021525\\Anaconda3\\envs\\geoharvester\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "2it [03:39, 111.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [1:12:09, 45.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [1:25:45, 56.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [1:27:11, 65.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [1:30:14, 77.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [1:33:18, 68.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [1:37:02, 92.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [1:39:17, 105.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [1:42:45, 84.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [1:44:24, 88.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping differing translation lengths!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39395it [1:57:41,  5.58it/s] \n"
     ]
    }
   ],
   "source": [
    "# iterate through the dataframe\n",
    "task = \"Extract a list of key words comma separated without adjectives in original language from the following text: \"\n",
    "en_trns_task = \"Translate the following list of words into a comma separated list in English: \"\n",
    "de_trns_task = \"Übersetze die folgende Liste von Wörtern in eine durch Komma getrennte Liste auf Deutsch: \"\n",
    "fr_trns_task = \"Traduisez la liste de mots suivante en une liste séparée par des virgules en francais: \"\n",
    "it_trns_task = \"Traduci il seguente elenco di parole in un elenco separato da virgole in italiano: \"\n",
    "\n",
    "df_kg = pd.DataFrame()\n",
    "\n",
    "for idx, row in tqdm(data.iterrows()):\n",
    "    if idx > 100:\n",
    "        continue\n",
    "    trns_dict = {\"ENG\":en_trns_task, \"DEU\":de_trns_task, \"ITA\":it_trns_task,'FRA':fr_trns_task}\n",
    "    if row['lang_3'] != 'NAN':\n",
    "        del trns_dict[row['lang_3']]\n",
    "    # filter rows with no abstract and use title instead\n",
    "    if row['abstract'] == 'nan' or row['abstract']==row['title'] or len(row['abstract'].split(' '))<5 or row['abstract'].startswith(('??',\n",
    "                                                                                                                                      'Es werden die Daten im Zeitraum',\n",
    "                                                                                                                                      'Link zu Metadaten:',\n",
    "                                                                                                                                      'https:',\n",
    "                                                                                                                                      'geo@bs.ch',\n",
    "                                                                                                                                      'info.geoportal@be.ch',\n",
    "                                                                                                                                      'sit@jura.ch',\n",
    "                                                                                                                                      'geodaten@sg.ch',\n",
    "                                                                                                                                      'info@example.com',\n",
    "                                                                                                                                      'agi@tg.ch',\n",
    "                                                                                                                                      'mail@lisag.ch',\n",
    "                                                                                                                                      'gis@bd.zh.ch',\n",
    "                                                                                                                                      'info.diffusion@vd.ch',\n",
    "                                                                                                                                      'webgis@swisstopo.ch')):\n",
    "        # llama_answer = ask_llama(task, row['title'], idx)\n",
    "        pass\n",
    "    else:\n",
    "        # generate LLM response with abstract and interpret it\n",
    "        kwds = read_keyowrds(ask_llama(task, row['abstract']))\n",
    "\n",
    "        df_kg = collect_keywords(kwds, row['lang_3'], trns_dict, df_kg)\n",
    "        # for lang in [k for k in trns_dict.keys()]:\n",
    "        #     llama_translation = ask_llama(trns_dict[lang], \", \".join(kwds), idx, check_response=False)\n",
    "        #     translations[lang] = read_translation(llama_translation)\n",
    "        # if check_length(translations, len(kwds)):\n",
    "        #     df = pd.DataFrame({row['lang_3']:kwds})\n",
    "        #     for lang in [k for k in trns_dict.keys()]:\n",
    "        #         df[lang] = translations[lang]\n",
    "        #         # data.loc[idx, 'kg_'+lang] = ','.join(translations[lang])\n",
    "        #     # data.loc[idx, 'kg_'+row['lang_3']] = ','.join(kwds)\n",
    "        #     df_kg = pd.concat([df_kg, df], axis=0, ignore_index=True)\n",
    "        # else:\n",
    "        #     print(\"Differing translation lengths!\")\n",
    "\n",
    "remove_rows = df_kg.applymap(lambda x: len(x.split(\" \"))).apply(sum, axis=1).loc[lambda x:x==4].index.tolist()\n",
    "df_kg.drop(remove_rows, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.to_pickle('kg_data_100.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = generate_knowledge_graph(df_kg, 'knowledge_graph', update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if \"Gefahrenkarte\" in find_edges_by_language(kg, 'german'):\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"carte d'alerte\",\n",
       " \"carte d'aléa\",\n",
       " 'carta di pericolo',\n",
       " 'géocarte dangereuse',\n",
       " 'carta dei pericoli',\n",
       " 'danger map',\n",
       " 'Gefahrenkarte']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_translation(kg, 'Gefahrenkarte', 'german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoharvester",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
